{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage.filters\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "# from nets import inception\n",
    "# from preprocessing import inception_preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image to features\n",
    "def feature_computation(image_arr):\n",
    "    \n",
    "#     image to numpy array\n",
    "\n",
    "#     image = Image.fromarray(image_arr)\n",
    "\n",
    "    image = image_arr   \n",
    "    \n",
    "    \n",
    "    features = []\n",
    "    laplacian0 = scipy.ndimage.filters.laplace(image[:,:,0])\n",
    "    laplacian1 = scipy.ndimage.filters.laplace(image[:,:,1])\n",
    "    laplacian2 = scipy.ndimage.filters.laplace(image[:,:,2])\n",
    "    \n",
    "#     lap_mat0 = np.matrix(laplacian[:,:,0])\n",
    "#     lap_mat1 = np.matrix(laplacian[:,:,1])\n",
    "#     lap_mat2 = np.matrix(laplacian[:,:,2])\n",
    "\n",
    "    lap_mat0 = laplacian0\n",
    "    lap_mat1 = laplacian1\n",
    "    lap_mat2 = laplacian2\n",
    "    \n",
    "    \n",
    "    \n",
    "    features.append(lap_mat0.sum())\n",
    "    features.append(lap_mat1.sum())\n",
    "    features.append(lap_mat2.sum())\n",
    "    \n",
    "#     image_gray = image.convert('LA')\n",
    "    image_gray = (image[:,:,0] + image[:,:,1] + image[:,:,2])/3\n",
    "#     gray_array = np.array(image_gray)[:,:,0]\n",
    "    gray_array = image_gray\n",
    "    edges = feature.canny(gray_array,sigma = 3,low_threshold=5, high_threshold=20)\n",
    "    max_val = np.amax(edges)\n",
    "\n",
    "    \n",
    "    for j in range(0,edges.shape[1]):\n",
    "        for i in range(0,edges.shape[0]):\n",
    "            if edges[i][j] > .1*max_val:\n",
    "                edges[i][j] = 0\n",
    "                if edges[i+1][j] < .1*max_val:\n",
    "                    break\n",
    "        for ii in range(0,edges.shape[0]):\n",
    "            i = edges.shape[0] - ii -1\n",
    "            if edges[i][j] > .1*max_val:\n",
    "                edges[i][j] = 0\n",
    "                if edges[i-1][j] < .1*max_val:\n",
    "                    break\n",
    "                    \n",
    "    features.append(edges.sum())\n",
    "    \n",
    "    return features\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_predictor(image_arr_list):\n",
    "    \n",
    "#     image = Image.fromarray(image_arr, 'RGB')\n",
    "\n",
    "\n",
    "    ind1,ind2,ind3,ind4 = image_arr_list.shape\n",
    "\n",
    "\n",
    "\n",
    "#     print(\"print input inside predictor \"+str(image_arr_list.shape))\n",
    "    print(\"print input list's length \"+str(ind1))\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0,ind1):\n",
    "        \n",
    "        print(i)\n",
    "        image_arr = image_arr_list[i,:,:,:]\n",
    "    \n",
    "    \n",
    "        feature_vec = feature_computation(image_arr)\n",
    "        model = joblib.load(\"radom_forest_model.pkl\")\n",
    "        single_prediction = model.predict([feature_vec])\n",
    "        if single_prediction == True:\n",
    "            predictions.append({\"True\":1,\"False\":0})\n",
    "        else:\n",
    "            predictions.append({\"True\":0,\"False\":1})\n",
    "            \n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image size after opened (130, 145)\n",
      "print image array size (145, 130, 3)\n",
      "print array after resized (130, 145, 3)\n",
      "print input list's length 3\n",
      "0\n",
      "1\n",
      "2\n",
      "print input list's length 3\n",
      "0\n",
      "1\n",
      "2\n",
      "print input list's length 3\n",
      "0\n",
      "1\n",
      "2\n",
      "print input list's length 1\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-824bcc297344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mim_resized\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlime_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLimeImageExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mexplanation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_forest_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_image_and_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhide_rest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmark_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lime\\lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[0mmodel_regressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_regressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 feature_selection=self.feature_selection)\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret_exp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lime\\lime_base.py\u001b[0m in \u001b[0;36mexplain_instance_with_data\u001b[1;34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mlabels_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighborhood_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         used_features = self.feature_selection(neighborhood_data,\n\u001b[0;32m    155\u001b[0m                                                \u001b[0mlabels_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "from lime import lime_image\n",
    "import time\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import glob\n",
    "\n",
    "\n",
    "image_for_explanation=[]\n",
    "for filename in glob.glob('./explain_images/*.png'):\n",
    "    im=Image.open(filename)\n",
    "    image_for_explanation.append(im.copy())\n",
    "\n",
    "#     image_raw = tf.image.decode_png(im, channels=3)\n",
    "#     image_for_explanation(image_raw.copy())\n",
    "    im.close()\n",
    "    \n",
    "# for im in image_for_explanation:\n",
    "# #     plt.imshow(im)\n",
    "# #     plt.show()\n",
    "#     print(str(feature_computation(im))+ \"prediction: \" + str(random_forest_predictor(im)) )\n",
    "\n",
    "\n",
    "image = image_for_explanation[9]\n",
    "id1 , id2 = image.size\n",
    "\n",
    "print(\"image size after opened \"+str(image.size))\n",
    "\n",
    "im_arr = np.asarray(image)\n",
    "\n",
    "\n",
    "print(\"print image array size \"+str(im_arr.shape))\n",
    "\n",
    "im_resized = np.reshape(im_arr,(id1,id2,3))\n",
    "print(\"print array after resized \"+str(im_resized.shape))\n",
    "\n",
    "\n",
    "test_image =  im_resized\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(test_image, random_forest_predictor, batch_size = 3, num_samples=10)\n",
    "temp, mask = explanation.get_image_and_mask(label=True, positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
